# Desaf√≠o Grandata

El objetivo del presente documento es documentar la soluci√≥n propuesta al enunciado provisto en el archivo `technical_challenge.pdf`.

## Tecnolog√≠as y herramientas

- Python  
- Apache Spark  
- Jupyter Notebooks  
- Docker  
- WSL2 (Windows Subsystem for Linux)

## Estructura del proyecto

```bash
.
‚îú‚îÄ‚îÄ Solucion               
    ‚îú‚îÄ‚îÄ desafio.ipynb               # Notebook principal con el desarrollo
    ‚îú‚îÄ‚îÄ inputs/                
    ‚îÇ   ‚îú‚îÄ‚îÄ files/                  # Datasets de entrada
    ‚îÇ   ‚îî‚îÄ‚îÄ config.json             # Archivo de configuraci√≥n usado en la notebook
    ‚îú‚îÄ‚îÄ resultado/                
    ‚îÇ   ‚îú‚îÄ‚îÄ grafico.png             # Imagen del resultado del ejercicio 1.3
    ‚îÇ   ‚îî‚îÄ‚îÄ resultado.gz.parquet    # Archivo resultado del ejercicio 1.1
‚îú‚îÄ‚îÄ technical_challenge.pdf         # Enunciado      
‚îî‚îÄ‚îÄ README.md                       # Este archivo
```

## Instalaci√≥n y ejecuci√≥n
Este proyecto fue desarrollado y probado en un entorno local Windows utilizando WSL2 y Docker Desktop.

Primero, instalar el subsistema de Linux (WSL2) con Ubuntu. Para ello, abrir PowerShell como administrador y ejecutar:

```bash
wsl --install -d Ubuntu
```

Luego, instalar Docker Desktop desde docker.com, asegur√°ndose de habilitar el soporte para WSL2 e integraci√≥n con Ubuntu.

Verificar que Docker est√© correctamente instalado con:

```bash
docker --version
```

Posteriormente, descargar la imagen oficial de Jupyter con PySpark:

```bash
docker pull jupyter/pyspark-notebook:x86_64-ubuntu-22.04
```

Finalmente, iniciar el contenedor montando el directorio actual para compartir archivos:

```bash
docker run -p 8888:8888 -v "$PWD":/home/jovyan/work jupyter/pyspark-notebook:x86_64-ubuntu-22.04
```

Al ejecutarlo, se mostrar√° una URL con un token para acceder a JupyterLab en el navegador, t√≠picamente en:

http://127.0.0.1:8888/lab?token=...

Los archivos locales estar√°n disponibles dentro del contenedor en la ruta /home/jovyan/work.

## Resultados: Ejercicio 1

A continuaci√≥n se muestran los resultados generados por el an√°lisis realizado en la notebook:

### Facturacion total por sms

391367

### üìä Visualizaci√≥n de llamadas por hora

![Gr√°fico de llamadas por hora](./solucion/resultado/grafico.png)

> El gr√°fico representa la cantidad total de llamadas realizadas por hora del d√≠a.

### üìÅ Archivo resultante

Se gener√≥ un archivo en formato **Parquet** con los resultados procesados:

üìé [`resultado.gz.parquet`](./solucion/resultado/resultado.gz.parquet)

> Este archivo contiene los datos procesados.

## Respuestas al enunciado: Ejercicio 2

Para priorizar los procesos productivos sobre los an√°lisis, recomiendendo configurar el CapacityScheduler de YARN con dos colas diferenciadas, asignando un 70%/30% a dos diferentes colas. Adem√°s, se se podrian limitar los recursos (CPU y memoria) por contenedor para evitar que un proceso monopolice el cluster y, cuando sea posible, programar los procesos m√°s intensivos fuera del horario laboral.

En cuanto a la estrategia para administrar la ejecuci√≥n intensiva de los procesos productivos, aconsejo dividir los datos en lotes peque√±os para permitir ejecuciones en ventanas cortas y continuas, evitando cargas masivas que saturen los recursos. El uso de Delta Lake como formato de almacenamiento mejora la eficiencia en lectura y actualizaci√≥n de datos respecto a Parquet.

Entre las herramientas de scheduling: Apache Airflow (conocimiento basico), crontab para tareas simples y plataformas como Databricks.
